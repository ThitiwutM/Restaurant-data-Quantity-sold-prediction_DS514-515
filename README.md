# üçΩÔ∏è Restaurant Data: Quantity Sold Prediction

This is a term project for the DS514/515 Data Science course at SWU, Thailand.

The project aims to explore insights from restaurant sales data and identify the key factors influencing quantity sold. In addition, we developed predictive models for quantity sold using Linear Regression and regularized regression techniques (Ridge, Lasso, and Elastic Net) to support restaurants in improving their performance and developing effective strategies to enhance sales.

üîç Project Workflow

The modeling workflow includes:

‚úîÔ∏è About dataset

‚úîÔ∏è Data cleaning

‚úîÔ∏è Exploratory Data Analysis (EDA)

‚úîÔ∏è Feature selection

‚úîÔ∏è Data pre-processing

‚úîÔ∏è Data pipeline development and Linear Regression

‚úîÔ∏è Model building and evaluation

---

‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô!!! ‡∏Ç‡∏≠‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤ DS514/515 Data Analytics ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏®‡∏£‡∏µ‡∏ô‡∏Ñ‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡∏ß‡∏¥‡πÇ‡∏£‡∏í

‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢ ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Linear Regression ‡πÅ‡∏•‡∏∞ Regularized Linear Regression ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà Ridge, Lasso, ‡πÅ‡∏•‡∏∞ Elastic Net ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏ú‡∏•

üîç Project Workflow

‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏É‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:

‚úîÔ∏è ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (About dataset)

‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data cleaning)

‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏≥‡∏£‡∏ß‡∏à (EDA)

‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Feature selection)

‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Pre-processing)

‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Data pipeline ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear regression

‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model building & evaluation)

---

## 1Ô∏è‚É£ ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (About dataset)

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å Kaggle ‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÇ‡∏î‡∏¢ ‡∏Ñ‡∏∏‡∏ì Alexand Chen (https://www.kaggle.com/datasets/alexandchen/restaurant-sales-report-2024-2025)

Dataset ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö csv ‡πÑ‡∏ü‡∏•‡πå ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å restaurant_dataset.csv (https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/restaurant_dataset.csv)

üìä ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:

- 10,000 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (records) ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 1 ‡∏°.‡∏Ñ. 2024 ‡∏ñ‡∏∂‡∏á 1 ‡∏°.‡∏Ñ. 2025

- 13 ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ (attributes)

üìÅ ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

- 9 ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà date, restaurant_id, restaurant_type, menu_item_name, meal_type, key_ingredients_tags, has_promotion (T/F), special_event (T/F), weather_condition (Sunny / Cloudy / Rainy)

- 4 ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (numerical data) ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö ‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞ ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà typical_ingredient_cost, observed_market_price, actual_selling_price, quantity_sold

üìã DATA DICTIONARY

| ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ (Attribute)      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (Description)               | ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Type) | ‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (Valid Range / Example) |
| ----------------------- | ------------------------------------ | ------------------------ | ------------------------------------------- |
| date                    | ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö dd/MM/yyyy)  | Date/DateTime            | 01/01/2024 ‚Äì 01/01/2025                     |
| restaurant_id           | ‡∏£‡∏´‡∏±‡∏™‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£                        | Number/Float             | 1 ‚Äì 50                                      |
| restaurant_type         | ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£                      | Text                     | Food Stall / Casual / Fine Dining           |
| menu_item_name          | ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°            | Text                     | Kaya Toast Set / Cendol / Teh Tarik         |
| meal_type               | ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏°‡∏∑‡πâ‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£                      | Text                     | Breakfast / Lunch / Dinner                  |
| key_ingredients_tags    | ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏ô‡∏π (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma) | Text                     | white bread, kaya, butter, ‚Ä¶                |
| typical_ingredient_cost | ‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì              | Number/Float             | 0.8 ‚Äì 9                                     |
| observed_market_price   | ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÑ‡∏î‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏ô‡∏π          | Number/Float             | 1.46 ‚Äì 56.29                                |
| actual_selling_price    | ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤                 | Number/Float             | 1.36 ‚Äì 83.09                                |
| quantity_sold           | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ (‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≤‡∏ô/‡∏´‡∏ô‡πà‡∏ß‡∏¢)  | Number/Float             | 0 ‚Äì 1668                                    |
| has_promotion           | ‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà                    | Boolean                  | True / False                                |
| special_event           | ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà            | Boolean                  | True / False                                |
| weather_condition       | ‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏Ç‡∏≤‡∏¢                    | Text                     | Sunny / Cloudy / Rainy                      |

---

## 2Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Cleaning)

üßπ Cleansing Summary

‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (Missing Data)
- ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Library
- ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå csv
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‚Üí ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ NULL
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 10,000 ‡πÅ‡∏ñ‡∏ß ‡πÅ‡∏•‡∏∞ 13 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå

‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Type Conversion)
- ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå date ‡∏à‡∏≤‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Äúobject‚Äù ‚Üí datetime64[ns]
- ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå restaurant_id ‡∏à‡∏≤‡∏Å ‚Äúint64‚Äù ‚Üí object

```python
# import numpy, pandas, matplotlib, seaborn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# read csv file
data = pd.read_csv('/content/drive/MyDrive/DS514.csv')
data.head()

# check data.info
data.info()

# change date from 'object' to 'date'
data['date'] = pd.to_datetime(data['date'])
data.info()

# change restaurant_id from 'int' to 'object'
data['restaurant_id'] = data['restaurant_id'].astype(str)
data.info()

# check data is NULL
data.isnull().sum()
```
data  information

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/data_info.jpg)

check NULL value

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/Check_NULL.jpg)

---

## 3Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏≥‡∏£‡∏ß‡∏à (Exploratory Data Analysis: EDA)

EDA 1 ‚Äì ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ (Quantity Sold Overview)

‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á quantity_sold ‡∏û‡∏ö‡∏ß‡πà‡∏≤
- ‡∏£‡πâ‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Fine Dining ‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏£‡πâ‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á 50 ‡πÅ‡∏´‡πà‡∏á
- ‡∏Å‡∏£‡∏≤‡∏ü Box-Whisker ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ ‡∏Ñ‡πà‡∏≤‡∏°‡∏±‡∏ò‡∏¢‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Fine Dining ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

```python
# summary table of average_quantity sold by restaurant_id sorting by descending of average_quantity sold
restaurant = data.groupby('restaurant_id')['quantity_sold'].mean().sort_values(ascending=False)
display(restaurant)

# bar plot the 'restaurant' data sorting by descending of average_quantity sold
plt.figure(figsize=(12,5))
plt.bar(restaurant.index, restaurant.values)
plt.ylabel('quantity_sold')
plt.show()

# summary table of sum_quantity sold by restaurant_id sorting by descending of sum_quantity sold
restaurant2 = data.groupby('restaurant_id')['quantity_sold'].sum().sort_values(ascending=False)
display(restaurant2)

# bar plot the 'restaurant2' data sorting by descending of sum_quantity sold
plt.figure(figsize=(12,5))
plt.bar(restaurant2.index, restaurant2.values)
plt.ylabel('quantity_sold')
plt.show()

# plot box plot of quantity_sold by restaurant type from data
plt.figure(figsize=(6,5))
sns.boxplot(x='restaurant_type', y='quantity_sold', data = data)
```
![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/EDA1_bargraph.jpg)

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/EDA1_boxplot.jpg)


EDA 2 ‚Äì ‡∏Å‡∏≤‡∏£‡∏î‡∏π‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ï‡∏•‡∏≠‡∏î 1 ‡∏õ‡∏µ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ (Trend & Correlation Analysis)
- ‡∏à‡∏≤‡∏Å‡∏Å‡∏£‡∏≤‡∏ü Time-series ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° (Trend) ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
- ‡πÅ‡∏ï‡πà‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏£‡∏≤‡∏¢‡∏õ‡∏µ‡∏Ç‡∏≠‡∏á quantity_sold ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡πâ‡∏≤‡∏ô Fine Dining ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏£‡πâ‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏∑‡πà‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (Correlation) ‡∏û‡∏ö‡∏ß‡πà‡∏≤:
- ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ cost, market_price, ‡πÅ‡∏•‡∏∞ selling_price ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å
- ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ quantity_sold ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‚Üí ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏•‡∏î‡∏•‡∏á

```python
# plot the line trend of quantity_sold by date and group by each restaurant_type (5 graph subplot)
plt.figure(figsize=(8,10))
for i, restaurant_type in enumerate(data['restaurant_type'].unique()):
    plt.subplot(5, 1, i+1)
    sns.lineplot(x='date', y='quantity_sold', data=data[data['restaurant_type'] == restaurant_type], label=restaurant_type)
    plt.title(restaurant_type)
    plt.xlabel('date')
    plt.ylabel('quantity_sold')
plt.tight_layout()
plt.show()

# correlation matrix plot of 'typical_ingredient_cost'	'observed_market_price'	'actual_selling_price'	'quantity_sold'
corr = data[['typical_ingredient_cost', 'observed_market_price', 'actual_selling_price', 'quantity_sold']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.show()
```

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/EDA_trend.jpg)

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/EDA2_correlation.jpg)


EDA 3 ‚Äì ‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏® / ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô / ‡∏≠‡∏µ‡πÄ‡∏ß‡∏ô‡∏ï‡πå (Weather, Promotion & Event Effects)

- ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà Sunny (251) ‡πÅ‡∏•‡∏∞ Cloudy (249) ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà Rainy (227) ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏•‡πá‡∏Å ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÑ‡∏î‡πâ‡∏¢‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏£‡∏≤‡∏ü Box-Whisker

- ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô (482) ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô (251) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏û‡∏¥‡πÄ‡∏®‡∏© (363) ‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏µ‡πÄ‡∏ß‡∏ô‡∏ï‡πå (282)

```python
# summary table of average_quantity sold by each weather_condition
season = data.groupby('weather_condition')['quantity_sold'].mean()
display(season)

# summary table of average_quantity sold by each weather_condition
season = data.groupby('weather_condition')['quantity_sold'].mean()
display(season)

# plot box-whisker plot of quantity_sold by each weather_condition
plt.figure(figsize=(3,5))
sns.boxplot(x='weather_condition', y='quantity_sold', data=data)

# plot box-whisker plot of quantity_sold by has_promotion
plt.figure(figsize=(3,5))
sns.boxplot(x='has_promotion', y='quantity_sold', data=data)

# plot box-whisker plot of quantity_sold by special_event
plt.figure(figsize=(3,5))
sns.boxplot(x='special_event', y='quantity_sold', data=data)
```

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/EDA_Weather-Promotion-Event.jpg)

---

## 4Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Feature Selection)

‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ Quantity_sold ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Features ‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö numeric ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡∏ö categorical ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
- numeric: lag1, actual_selling_price
- categorical: weather_condition, has_promotion, special_event

üìå ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•

‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 5 ‡∏£‡πâ‡∏≤‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà
restaurant_id = ‚Äò32‚Äô, ‚Äò6‚Äô, ‚Äò42‚Äô, ‚Äò10‚Äô, ‚Äò38‚Äô
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ (Quantity_sold)

‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å = 1,027 records

üÜï ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà (‚Äúlag1‚Äù)

‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡∏ä‡∏∑‡πà‡∏≠ lag1 ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á quantity_sold ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô Feature ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ time dependency

```python
# Prepare more data for modeling
# focus on restaurant_id '32' '6' '42' '10 '38'
model_data = data[data['restaurant_id'].isin(['32', '6', '42', '10', '38'])]
model_data.head()

# summary of how many row record in each restaurant_id of model_data
model_data.groupby('restaurant_id').size()

# create lag1 of quantity_sold and diff(quantity_sold and lag1) of model_data
model_data['lag1'] = model_data.groupby(['restaurant_id','menu_item_name'])['quantity_sold'].shift(1)
model_data['diff'] = model_data['quantity_sold'] - model_data['lag1']
model_data.tail()
```

---

## 5Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Pre-processing)

‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
- Import library
- Set ‚Äúfeatures‚Äù and ‚Äútarget‚Äù
- Remove ‚ÄúNULL‚Äù value of lag1
- Train/test split (80/20)
- Define numerical features / categorical features
- Check size of data

Pre-processing
- Numerical Features ‚Üí StandardScaler
- Categorical Features ‚Üí One-Hot Encoder

```python
rom sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error

# --- 1. Feature and Target Definition ---

# Define the target variable (y) and the predictor variables (X)
X = model_data[['lag1', 'actual_selling_price', 'weather_condition', 'has_promotion', 'special_event']]
y = model_data['quantity_sold']

# Remove NULL value from lag1
X = X.dropna()
y = y[X.index]

# Split data into training and testing sets (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# shuffle=False is crucial for time-series data to maintain chronological order

# Define feature types for the ColumnTransformer
numerical_features = ['lag1', 'actual_selling_price']
categorical_features = ['weather_condition', 'has_promotion', 'special_event']

# summary data_size of X_train, X_test, y_train, y_test
print("X_train size:", X_train.shape)
print("X_test size:", X_test.shape)
print("y_train size:", y_train.shape)
print("y_test size:", y_test.shape)

# --- 2. Data Preprocessing Pipeline (Scaling and Encoding) ---

# Create the preprocessing pipeline using ColumnTransformer
# Apply Standard Scaling to numerical features
# Apply One-Hot Encoding to categorical features (handle_unknown='ignore' prevents error on unseen category)

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'), categorical_features)
    ],
    remainder='passthrough' # Keep any columns not specified (if any)
)
```

---

## 6Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Data Pipeline ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear Regression

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á Data Pipeline ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:

üîß Data Pipeline = Preprocessor + Linear Regression

Pipeline ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô
- Standard Scaling ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric features
- One-Hot Encoding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö categorical features
- ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear Regression
‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏£‡∏ß‡∏°‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô

‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear Regression
|            | ‡∏Ñ‡πà‡∏≤                                       |
| ---------------- | ----------------------------------------- |
| **Coefficients** | 37.02, -62.21, 14.57, 13.10, 86.55, 97.70 |
| **Intercept**    | 163.90                                    |
| **R¬≤ Score**     | **0.4315**                                |
| **MAE**          | 96.96                                     |
| **RMSE**         | 127.86                                    |


```python
# --- 3. Model 1: Baseline Linear Regression ---

# Create the full pipeline for Linear Regression
lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                              ('regressor', LinearRegression())])

print("--- Baseline Linear Regression ---")
lr_pipeline.fit(X_train, y_train)
lr_predictions = lr_pipeline.predict(X_test)
print('Coefficients:', lr_pipeline.named_steps['regressor'].coef_)
print('Intercept:', lr_pipeline.named_steps['regressor'].intercept_)
print("R2 Score:", r2_score(y_test, lr_predictions))
print("MAE:", mean_absolute_error(y_test, lr_predictions))
print("RMSE:", root_mean_squared_error(y_test, lr_predictions))
```

---

## 7Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Building & Evaluation)

‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Regularized Linear Regression ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Polynomial Features ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô (non-linear relationship) ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ (quantity_sold)

üîß Model Pipeline

Pipeline ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô:

Pipeline = Preprocessor + PolynomialFeatures + Ridge / Lasso / ElasticNet

‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
- Standard Scaling ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric features
- One-Hot Encoding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö categorical features
- Polynomial Features (degree 1‚Äì10)
- Regularized Regression (Ridge / Lasso / Elastic Net)

‚öôÔ∏è Hyperparameter Tuning

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ GridSearchCV

üîç Param Grid ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
- Polynomial degree: 1 ‚Üí 10
- Alpha (Œ±): 10‚Åª‚Å∂ ‚Üí 10¬≥
- Elastic Net l1_ratio: 0 ‚Üí 1
- Cross-validation: 5 folds
- Scoring metric: 'r2'

üèÜ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (Evaluation Metrics)

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å:
- R¬≤ Score (Coefficient of Determination)
- MAE (Mean Absolute Error)
- RMSE (Root Mean Square Error)

|                      | Ridge  | Lasso        | Elastic Net |
| -------------------------- | ------ | ------------ | ----------- |
| **Best Polynomial Degree** | 3      | 3            | 4           |
| **Best Alpha**             | 100.0  | 1            | 0.01        |
| **Best L1 Ratio**          | ‚Äì      | ‚Äì            | 0.33        |
| **R¬≤ (Train)**             | 0.5365 | 0.5470       | 0.6192  |
| **R¬≤ (Test)**              | 0.5444 | **0.5639** ‚≠ê | 0.5285      |
| **MAE (Train)**            | 79.17  | 78.91        | 72.14   |
| **MAE (Test)**             | 87.38  | **86.09**  ‚≠ê  | 88.20       |
| **RMSE (Train)**           | 101.38 | 100.23       | 91.89   |
| **RMSE (Test)**            | 114.47 | **111.99**  ‚≠ê | 116.45      |

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/Hyperparameter_tuning_lasso.jpg)

```python
# --- 4. Model 2 Ridge Regression with polynomial feature ---

from sklearn.preprocessing import PolynomialFeatures

polynomial_ridge_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('polynomialfeatures', PolynomialFeatures()), # Placeholder, degree will be tuned
    ('regressor', Ridge())
])

param_grid = {
    # Alpha values for Ridge regularization (log scale for better searching)
    'regressor__alpha': np.logspace(-6, 3, 10),
    # Polynomial degrees to test (1 to 10)
    'polynomialfeatures__degree': np.arange(1, 11)
}

print("--- Ridge Regression with Polynomial Features Tuning ---")
grid_search = GridSearchCV(
    polynomial_ridge_pipeline,
    param_grid=param_grid,
    cv=5,
    scoring='r2'
)

grid_search.fit(X_train, y_train)

Ridge_best_estimator = grid_search.best_estimator_
Ridge_predictions = Ridge_best_estimator.predict(X_test)

best_params = grid_search.best_params_
best_degree = best_params['polynomialfeatures__degree']
best_alpha = best_params['regressor__alpha']

# Evaluation
r2_train = r2_score(y_train, Ridge_best_estimator.predict(X_train))
r2_test = r2_score(y_test, Ridge_predictions)
mae_train = mean_absolute_error(y_train, Ridge_best_estimator.predict(X_train))
mae_test = mean_absolute_error(y_test, Ridge_predictions)
rmse_train = root_mean_squared_error(y_train, Ridge_best_estimator.predict(X_train))
rmse_test = root_mean_squared_error(y_test, Ridge_predictions)

print("\n--- Optimized Model Results ---")
print(f"Best Polynomial Degree: {best_degree}")
print(f"Best Alpha: {best_alpha:.6f}")
print(f"\nR2 Score on Training Set: {r2_train:.4f}")
print(f"R2 Score on Test Set: {r2_test:.4f}")
print(f"MAE on Training Set: {mae_train:.2f}")
print(f"MAE on Test Set: {mae_test:.2f}")
print(f"RMSE on Training Set: {rmse_train:.2f}")
print(f"RMSE on Test Set: {rmse_test:.2f}")

# --- 5. Model 3 Lasso Regression with polynomial feature ---

from sklearn.preprocessing import PolynomialFeatures

polynomial_lasso_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('polynomialfeatures', PolynomialFeatures()), # Placeholder, degree will be tuned
    ('regressor', Lasso())
])

param_grid = {
    # Alpha values for Lasso regularization
    'regressor__alpha': np.logspace(-6, 3, 10),
    # Polynomial degrees to test (1 to 10)
    'polynomialfeatures__degree': np.arange(1, 11),
    # iteration
    'regressor__max_iter': [100]
}

print("--- Lasso Regression with Polynomial Features Tuning ---")
grid_search = GridSearchCV(
    polynomial_lasso_pipeline,
    param_grid=param_grid,
    cv=5,
    scoring='r2'
)

grid_search.fit(X_train, y_train)

Lasso_best_estimator = grid_search.best_estimator_
Lasso_predictions = Lasso_best_estimator.predict(X_test)

best_params = grid_search.best_params_
best_alpha = best_params['regressor__alpha']
best_degree = best_params['polynomialfeatures__degree']

# Evaluation
r2_train = r2_score(y_train, Lasso_best_estimator.predict(X_train))
r2_test = r2_score(y_test, Lasso_predictions)
mae_train = mean_absolute_error(y_train, Lasso_best_estimator.predict(X_train))
mae_test = mean_absolute_error(y_test, Lasso_predictions)
rmse_train = root_mean_squared_error(y_train, Lasso_best_estimator.predict(X_train))
rmse_test = root_mean_squared_error(y_test, Lasso_predictions)

print("\n--- Optimized Model Results ---")
print(f"Best Polynomial Degree: {best_degree}")
print(f"Best Alpha: {best_alpha:.6f}")
print(f"\nR2 Score on Training Set: {r2_train:.4f}")
print(f"R2 Score on Test Set: {r2_test:.4f}")
print(f"MAE on Training Set: {mae_train:.2f}")
print(f"MAE on Test Set: {mae_test:.2f}")
print(f"RMSE on Training Set: {rmse_train:.2f}")
print(f"RMSE on Test Set: {rmse_test:.2f}")

# --- 6. Model 4 Elastuc Net Regression with polynomial feature ---

from sklearn.preprocessing import PolynomialFeatures

polynomial_elastic_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('polynomialfeatures', PolynomialFeatures()), # Placeholder, degree will be tuned
    ('regressor', ElasticNet())
])

param_grid = {
    # Alpha values for Elastic Net
    'regressor__alpha': np.logspace(-6, 3, 10),
    'regressor__l1_ratio': np.linspace(0, 1, 10),
    # Polynomial degrees to test (1 to 10)
    'polynomialfeatures__degree': np.arange(1, 11),
    # iteration
    'regressor__max_iter': [100]
}

print("--- Elastic Net Regression with Polynomial Features Tuning ---")
grid_search = GridSearchCV(
    polynomial_elastic_pipeline,
    param_grid=param_grid,
    cv=5,
    scoring='r2'
)

grid_search.fit(X_train, y_train)

Elastic_best_estimator = grid_search.best_estimator_
Elastic_predictions = Elastic_best_estimator.predict(X_test)

best_params = grid_search.best_params_
best_alpha = best_params['regressor__alpha']
best_l1_ratio = best_params['regressor__l1_ratio']
best_degree = best_params['polynomialfeatures__degree']

# evaluation
r2_train = r2_score(y_train, Elastic_best_estimator.predict(X_train))
r2_test = r2_score(y_test, Elastic_predictions)
mae_train = mean_absolute_error(y_train, Elastic_best_estimator.predict(X_train))
mae_test = mean_absolute_error(y_test, Elastic_predictions)
rmse_train = root_mean_squared_error(y_train, Elastic_best_estimator.predict(X_train))
rmse_test = root_mean_squared_error(y_test, Elastic_predictions)

print("\n--- Optimized Model Results ---")
print(f"Best Polynomial Degree: {best_degree}")
print(f"Best Alpha: {best_alpha:.6f}")
print(f"Best L1 Ratio: {best_l1_ratio:.2f}")
print(f"\nR2 Score on Training Set: {r2_train:.4f}")
print(f"R2 Score on Test Set: {r2_test:.4f}")
print(f"MAE on Training Set: {mae_train:.2f}")
print(f"MAE on Test Set: {mae_test:.2f}")
print(f"RMSE on Training Set: {rmse_train:.2f}")
print(f"RMSE on Test Set: {rmse_test:.2f}")

results = pd.DataFrame(grid_search.cv_results_)

heatmap_data = results.pivot_table(
    values='mean_test_score',
    index='param_polynomialfeatures__degree',
    columns='param_regressor__alpha'
)

heatmap_data = heatmap_data.sort_index(axis=1)

plt.figure(figsize=(10, 8))

alpha_labels = [f'{a:.0e}' for a in heatmap_data.columns]

sns.heatmap(
    heatmap_data,
    annot=True,          # Show R2 values on the heatmap
    annot_kws={'size': 7},
    fmt=".3f",           # Format R2 values to 3 decimal places
    cmap="viridis",      # Color map: 'viridis' is a good sequential choice
    cbar_kws={'label': 'Cross-Validated R2 Score'}
)

plt.xlabel(r'Lasso $\alpha$ (Log Scale)', fontsize=12)
plt.ylabel('Polynomial Degree', fontsize=12)
plt.title(r'R2 Score Heatmap: Tuning $\alpha$ and Polynomial Degree', fontsize=14)

# Apply the log scale labels to the actual tick marks
plt.xticks(ticks=np.arange(len(alpha_labels)), labels=alpha_labels, rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()
```

---

## üèÅ ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (Conclusion and Closing Session)

‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏û‡∏ö‡∏ß‡πà‡∏≤ Lasso Regression ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ R¬≤ ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ MAE ‡πÅ‡∏•‡∏∞ RMSE ‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡∏Ñ‡πà‡∏≤ R¬≤ ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡πà‡∏≥ ‡πÄ‡∏û‡∏µ‡∏¢‡∏á 0.5639 ‡∏ã‡∏∂‡πà‡∏á‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÑ‡∏î‡πâ

![](https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/model%20results.jpg)

‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà:
- ‡πÉ‡∏ä‡πâ numerical features ‡πÅ‡∏ó‡∏ô categorical ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥ ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ù‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏≠‡∏≤‡∏´‡∏≤‡∏£
- ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Time-based split ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏° (random split) ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤ (time-series)
- ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÄ‡∏ä‡πà‡∏ô kNN, SVM ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ô‡∏µ‡πâ
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ SHAP ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏î‡∏°‡∏µ‡∏ú‡∏•‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ code python ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ï‡πá‡∏° ‡πÜ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å link ‡∏ô‡∏µ‡πâ ‚Üí https://github.com/ThitiwutM/Restaurant-data-Quantity-sold-prediction_DS514-515/blob/main/DS514-515%20Quantity_sold%20prediction.ipynb

---

‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏°‡∏≤‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏ï‡∏≠‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢!!! ‡πÄ‡∏£‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏≠‡∏µ‡∏Å‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏π‡πà‡∏Ç‡∏ô‡∏≤‡∏ô‡∏Å‡∏±‡∏ô ‡∏ô‡∏±‡πà‡∏ô‡∏Ñ‡∏∑‡∏≠...

üìä ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤ DS512/513: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£

‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠ ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏£‡∏£‡∏ì‡∏ô‡∏≤ (Excel), ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏´‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (Excel) ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡πÄ‡∏ä‡∏¥‡∏á‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö (Tableau) ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô ‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡∏ô, ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏û‡∏¥‡πÄ‡∏®‡∏©, ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡πâ‡∏≤‡∏ô ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÅ‡∏•‡∏∞‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡πÉ‡∏´‡πâ‡∏£‡πâ‡∏≤‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

üîç ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Project Workflow)

‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:

‚úîÔ∏è ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (About dataset)
‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Cleaning)
‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏≥‡∏£‡∏ß‡∏à (Exploratory Data Analysis, EDA)
‚úîÔ∏è ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î (Data Visualization & Dashboard)

üìå ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ üëá

üîó GitHub Repository: https://github.com/ThitiwutM/Restaurant-data-insights-and-analysis_DS512-513
